{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA Topic Modelling in Python:  Example 1\n",
    "\n",
    "This notebook is a use case of Gensim’s LDA model based on the \"LDA Topic Modelling in Python\" [Medium article](https://medium.com/swlh/lda-topic-modelling-in-python-7e9d08a64f33) posted by George Pipis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the data and required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>publish_date</th>\n",
       "      <th>headline_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20030219</td>\n",
       "      <td>aba decides against community broadcasting lic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20030219</td>\n",
       "      <td>act fire witnesses must be aware of defamation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20030219</td>\n",
       "      <td>a g calls for infrastructure protection summit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz staff in aust strike for pay rise</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20030219</td>\n",
       "      <td>air nz strike to affect australian travellers</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   publish_date                                      headline_text\n",
       "0      20030219  aba decides against community broadcasting lic...\n",
       "1      20030219     act fire witnesses must be aware of defamation\n",
       "2      20030219     a g calls for infrastructure protection summit\n",
       "3      20030219           air nz staff in aust strike for pay rise\n",
       "4      20030219      air nz strike to affect australian travellers"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import gensim\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "documents = pd.read_csv('news-data.csv');\n",
    "documents.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aba decides against community broadcasting licence\n",
      "act fire witnesses must be aware of defamation\n",
      "a g calls for infrastructure protection summit\n",
      "air nz staff in aust strike for pay rise\n",
      "air nz strike to affect australian travellers\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    print(documents.headline_text[i])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectoriser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "vect = CountVectorizer(min_df=20, # remove tokens that don't appear in at least 20 documents\n",
    "                       max_df=0.2, # remove tokens that appear in more than 20% of the documents\n",
    "                       stop_words='english', # remove stop words\n",
    "                       token_pattern='(?u)\\\\b\\\\w\\\\w\\\\w+\\\\b') # find three-letter tokens\n",
    "\n",
    "X = vect.fit_transform(documents.headline_text) # fit and transform the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting our sparse matrix to a dense Gensim structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert sparse matrix to dense gensim corpus\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping from word IDs to words (To be used in LdaModel's id2word parameter)\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the gensim.models.ldamodel.LdaModel constructor to estimate \n",
    "# LDA model parameters on the corpus, and save to the variable `ldamodel`\n",
    "\n",
    "ldamodel = gensim.models.LdaMulticore(corpus=corpus, \n",
    "                                      id2word=id_map, \n",
    "                                      passes=2,\n",
    "                                      random_state=5, \n",
    "                                      num_topics=10, \n",
    "                                      workers=2)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring the topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.014*\"west\" + 0.013*\"high\" + 0.012*\"market\" + 0.011*\"qld\" + 0.009*\"rise\" + 0.009*\"tax\" + 0.008*\"nsw\" + 0.008*\"share\" + 0.008*\"premier\" + 0.007*\"business\"\n",
      "\n",
      "\n",
      "Topic: 1 \n",
      "Words: 0.015*\"open\" + 0.013*\"live\" + 0.012*\"time\" + 0.012*\"report\" + 0.011*\"island\" + 0.010*\"australia\" + 0.009*\"commission\" + 0.009*\"says\" + 0.009*\"inquiry\" + 0.009*\"western\"\n",
      "\n",
      "\n",
      "Topic: 2 \n",
      "Words: 0.026*\"government\" + 0.019*\"nsw\" + 0.016*\"says\" + 0.014*\"health\" + 0.013*\"election\" + 0.012*\"indigenous\" + 0.011*\"calls\" + 0.011*\"council\" + 0.011*\"labor\" + 0.009*\"help\"\n",
      "\n",
      "\n",
      "Topic: 3 \n",
      "Words: 0.014*\"afl\" + 0.012*\"win\" + 0.011*\"2015\" + 0.010*\"change\" + 0.009*\"energy\" + 0.009*\"australia\" + 0.009*\"media\" + 0.009*\"week\" + 0.008*\"final\" + 0.008*\"talks\"\n",
      "\n",
      "\n",
      "Topic: 4 \n",
      "Words: 0.024*\"south\" + 0.023*\"adelaide\" + 0.015*\"rural\" + 0.014*\"national\" + 0.013*\"perth\" + 0.011*\"city\" + 0.010*\"community\" + 0.009*\"hobart\" + 0.009*\"students\" + 0.009*\"aboriginal\"\n",
      "\n",
      "\n",
      "Topic: 5 \n",
      "Words: 0.031*\"queensland\" + 0.024*\"coast\" + 0.021*\"north\" + 0.016*\"australia\" + 0.015*\"gold\" + 0.015*\"wins\" + 0.011*\"people\" + 0.010*\"korea\" + 0.010*\"australias\" + 0.009*\"marriage\"\n",
      "\n",
      "\n",
      "Topic: 6 \n",
      "Words: 0.028*\"australian\" + 0.020*\"court\" + 0.017*\"sex\" + 0.017*\"interview\" + 0.016*\"years\" + 0.014*\"child\" + 0.011*\"crash\" + 0.010*\"police\" + 0.010*\"abuse\" + 0.009*\"road\"\n",
      "\n",
      "\n",
      "Topic: 7 \n",
      "Words: 0.026*\"trump\" + 0.020*\"day\" + 0.013*\"donald\" + 0.012*\"tasmania\" + 0.011*\"turnbull\" + 0.011*\"australia\" + 0.010*\"2016\" + 0.009*\"australian\" + 0.009*\"nrl\" + 0.008*\"john\"\n",
      "\n",
      "\n",
      "Topic: 8 \n",
      "Words: 0.024*\"world\" + 0.022*\"new\" + 0.013*\"water\" + 0.013*\"power\" + 0.011*\"news\" + 0.010*\"work\" + 0.010*\"centre\" + 0.010*\"victorian\" + 0.009*\"school\" + 0.009*\"hospital\"\n",
      "\n",
      "\n",
      "Topic: 9 \n",
      "Words: 0.040*\"man\" + 0.034*\"police\" + 0.015*\"woman\" + 0.015*\"charged\" + 0.015*\"murder\" + 0.015*\"melbourne\" + 0.014*\"country\" + 0.013*\"attack\" + 0.012*\"car\" + 0.011*\"death\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in ldamodel.print_topics(-1):\n",
    "    print(\"Topic: {} \\nWords: {}\".format(idx, topic))\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "✏️ We can see the key words of each topic. For example the Topic 6 contains words such as “ court”, “ police”, “ murder” and the Topic 7 contains words such as “ donald”, “ trump “ etc"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Distribution\n",
    "\n",
    "### Getting probabilities for belonging to each topic "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a g calls for infrastructure protection summit\n",
      "(0, 0.21994263)\n",
      "(1, 0.020007217)\n",
      "(2, 0.41983947)\n",
      "(3, 0.22017446)\n",
      "(4, 0.020006038)\n",
      "(5, 0.020006038)\n",
      "(6, 0.020006038)\n",
      "(7, 0.020006038)\n",
      "(8, 0.020006038)\n",
      "(9, 0.020006038)\n"
     ]
    }
   ],
   "source": [
    "my_document = documents.headline_text[2]\n",
    "print(my_document)\n",
    "\n",
    "def topic_distribution(string_input):\n",
    "    string_input = [string_input]\n",
    "    X = vect.transform(string_input)\n",
    "    corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "    output = list(ldamodel[corpus])[0]\n",
    "    return output\n",
    "\n",
    "for i in topic_distribution(my_document):\n",
    "    print(i)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this document is more likely to belong to topic 2 with a\n",
    "41% probability. Let’s recall topic 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2,\n",
       " '0.026*\"government\" + 0.019*\"nsw\" + 0.016*\"says\" + 0.014*\"health\" + 0.013*\"election\" + 0.012*\"indigenous\" + 0.011*\"calls\" + 0.011*\"council\" + 0.011*\"labor\" + 0.009*\"help\"')"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ldamodel.print_topics(-1)[2]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting a single topic prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def topic_prediction(my_document):\n",
    "    string_input = [my_document]\n",
    "    X = vect.transform(string_input)\n",
    "    # Convert sparse matrix to gensim corpus.\n",
    "    corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "    output = list(ldamodel[corpus])[0]\n",
    "    topics = sorted(output,key=lambda x:x[1],reverse=True)\n",
    "    return topics[0][0]\n",
    "\n",
    "topic_prediction(my_document)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion from the authors:\n",
    "\n",
    "Additional suggestions: TF-IDF, lemmatisation/stemming etc."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (default, Oct 18 2022, 12:41:40) \n[Clang 14.0.0 (clang-1400.0.29.202)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
